{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twitter Sentiment Analysis using NLP\n",
    "\n",
    "# Install tweepy - pip install tweepy\n",
    "\n",
    "# Importing the libraries\n",
    "import tweepy\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "from tweepy import OAuthHandler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Please change with your own consumer key, consumer secret, access token and access secret\n",
    "# Initializing the keys\n",
    "consumer_key = 's7KQltVS70Lf9JdBo9eVib1S8'\n",
    "consumer_secret = 'sDnfGILJCDwtEN4m5JTGy57aaU5ZvQnYJyYZVpdWB8VNxZF6KJ' \n",
    "access_token = '384169077-tqsgMfPpKPvDo7Q8IqbqjKhTmOzYs3JHRmrakBEw'\n",
    "access_secret ='UQm3rFyI8GimHVQhPdUUfwSjbSN4NU7shdBT51WdyYEh0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the tokens\n",
    "auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    "args = ['NTRMahanayakudu'];\n",
    "api = tweepy.API(auth,timeout=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching the tweets\n",
    "list_tweets = []\n",
    "\n",
    "query = args[0]\n",
    "if len(args) == 1:\n",
    "    for status in tweepy.Cursor(api.search,q=query+\" -filter:retweets\",lang='en',result_type='recent',geocode=\"22.1568,89.4332,500km\").items(100):\n",
    "        list_tweets.append(status.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Who is in the picture? \\nOptions 1. #SrNTR 2.#BalaKrishna 3. #kalyanram 4. #jrNTR \\n#NTRBiopic #NTRMahanayakudu‚Ä¶ https://t.co/vbihWQYm9k', '#NTRKathanayakudu #January 9th\\n#NTRMahanayakudu #February 7th\\n#NTRBiopic #Audio On 21st Dec.....\\nIm #Waiting üëçüëçüëç‚Ä¶ https://t.co/mdmBla6rML', 'Trailer and Audio release of #NTRBiopic on 21 Dec 2018... #NTRKathanayakudu will release on 9 Jan 2019...‚Ä¶ https://t.co/dGgDjq028k', 'Happy Birthday Dear  \\n  @RanaDaggubati üéÇ\\nWishing you happiness, good health and a great year ahead.üéâ\\n\\nBest wishes f‚Ä¶ https://t.co/ZKZ4f2BuCf', '#Rajarshi\\nwhat a look of #balakrishna \\n#NTRBiopic \\n#NTRMahanayakudu \\n#balaiyya https://t.co/Ztouoxre0P', 'https://t.co/7q0zdpuDXv\\n2nd single #NTRKathanayakudu #NTRMahanayakudu #NTRBiopic #JaiBalayya', '#NTRBiopic Second Single #Rajarshi Song Release Date &amp; Time Changed To Dec 12th at 10.31 PM\\n\\n#NTRKathanayakudu‚Ä¶ https://t.co/V4YhdOH9Om']\n"
     ]
    }
   ],
   "source": [
    "print(list_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-9c876a3907cc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Loading the vectorizer and classfier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'classifier.pickle'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mclassifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mEOFError\u001b[0m: Ran out of input"
     ]
    }
   ],
   "source": [
    "# Loading the vectorizer and classfier\n",
    "with open('classifier.pickle','rb') as f:\n",
    "    classifier = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnsupportedOperation",
     "evalue": "read",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnsupportedOperation\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-0e18b3e8bd7b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tfidfmodel.pickle'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mtfidf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mUnsupportedOperation\u001b[0m: read"
     ]
    }
   ],
   "source": [
    "\n",
    "with open('tfidfmodel.pickle','wb') as f:\n",
    "    tfidf = pickle.load(f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-34f4d15b232b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tfidfmodel.pickle'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mtfidf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mEOFError\u001b[0m: Ran out of input"
     ]
    }
   ],
   "source": [
    "with open('tfidfmodel.pickle','rb') as f:\n",
    "    tfidf = pickle.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "who is in the picture options srntr balakrishna kalyanram jrntr ntrbiopic ntrmahanayakudu \n",
      " ntrkathanayakudu january th ntrmahanayakudu february th ntrbiopic audio on st dec im waiting \n",
      "trailer and audio release of ntrbiopic on dec ntrkathanayakudu will release on jan \n",
      "happy birthday dear ranadaggubati wishing you happiness good health and great year ahead best wishes \n",
      " rajarshi what look of balakrishna ntrbiopic ntrmahanayakudu balaiyya \n",
      " nd single ntrkathanayakudu ntrmahanayakudu ntrbiopic jaibalayya\n",
      " ntrbiopic second single rajarshi song release date amp time changed to dec th at pm ntrkathanayakudu \n"
     ]
    }
   ],
   "source": [
    "# Preprocessing the tweets\n",
    "for tweet in list_tweets:\n",
    "    tweet = re.sub(r\"^https://t.co/[a-zA-Z0-9]*\\s\", \" \", tweet)\n",
    "    tweet = re.sub(r\"\\s+https://t.co/[a-zA-Z0-9]*\\s\", \" \", tweet)\n",
    "    tweet = re.sub(r\"\\s+https://t.co/[a-zA-Z0-9]*$\", \" \", tweet)\n",
    "    tweet = tweet.lower()\n",
    "    tweet = re.sub(r\"that's\",\"that is\",tweet)\n",
    "    tweet = re.sub(r\"there's\",\"there is\",tweet)\n",
    "    tweet = re.sub(r\"what's\",\"what is\",tweet)\n",
    "    tweet = re.sub(r\"where's\",\"where is\",tweet)\n",
    "    tweet = re.sub(r\"it's\",\"it is\",tweet)\n",
    "    tweet = re.sub(r\"who's\",\"who is\",tweet)\n",
    "    tweet = re.sub(r\"i'm\",\"i am\",tweet)\n",
    "    tweet = re.sub(r\"she's\",\"she is\",tweet)\n",
    "    tweet = re.sub(r\"he's\",\"he is\",tweet)\n",
    "    tweet = re.sub(r\"they're\",\"they are\",tweet)\n",
    "    tweet = re.sub(r\"who're\",\"who are\",tweet)\n",
    "    tweet = re.sub(r\"ain't\",\"am not\",tweet)\n",
    "    tweet = re.sub(r\"wouldn't\",\"would not\",tweet)\n",
    "    tweet = re.sub(r\"shouldn't\",\"should not\",tweet)\n",
    "    tweet = re.sub(r\"can't\",\"can not\",tweet)\n",
    "    tweet = re.sub(r\"couldn't\",\"could not\",tweet)\n",
    "    tweet = re.sub(r\"won't\",\"will not\",tweet)\n",
    "    tweet = re.sub(r\"\\W\",\" \",tweet)\n",
    "    tweet = re.sub(r\"\\d\",\" \",tweet)\n",
    "    tweet = re.sub(r\"\\s+[a-z]\\s+\",\" \",tweet)\n",
    "    tweet = re.sub(r\"\\s+[a-z]$\",\" \",tweet)\n",
    "    tweet = re.sub(r\"^[a-z]\\s+\",\" \",tweet)\n",
    "    tweet = re.sub(r\"\\s+\",\" \",tweet)\n",
    "    print(tweet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tfidf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-bc3371f5ed14>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtweet\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\":\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tfidf' is not defined"
     ]
    }
   ],
   "source": [
    "    sent = tfidf.predict(vectorizer.transform([tweet]).toarray())\n",
    "    print(tweet,\":\",sent)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
