{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.nn.utils import clip_grad_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Dictionary(object):\n",
    "    def __init__(self):\n",
    "        self.word2idx = {}\n",
    "        self.idx2word = {}\n",
    "        self.idx = 0\n",
    "\n",
    "    def add_word(self, word):\n",
    "        if word not in self.word2idx:\n",
    "            self.word2idx[word] = self.idx\n",
    "            self.idx2word[self.idx] = word\n",
    "            self.idx += 1\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextProcess(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.dictionary = Dictionary()\n",
    "\n",
    "    def get_data(self, path, batch_size=20):\n",
    "        with open(path, 'r') as f:\n",
    "            tokens = 0\n",
    "            for line in f:\n",
    "                words = line.split() + ['<eos>']\n",
    "                tokens += len(words)\n",
    "                #print(tokens)\n",
    "                for word in words: \n",
    "                    self.dictionary.add_word(word)  \n",
    "        #Create a 1-D tensor that contains the index of all the words in the file+\n",
    "        print(tokens)\n",
    "        rep_tensor = torch.LongTensor(tokens)\n",
    "        #print(rep_tensor)\n",
    "        index = 0\n",
    "        with open(path, 'r') as f:\n",
    "            for line in f:\n",
    "                words = line.split() + ['<eos>']\n",
    "                for word in words:\n",
    "                    rep_tensor[index] = self.dictionary.word2idx[word]\n",
    "                    index += 1\n",
    "        #Find out how many batches we need            \n",
    "        num_batches = rep_tensor.shape[0] // batch_size  \n",
    "        print(rep_tensor)\n",
    "        print(rep_tensor.shape[0])\n",
    "        print(num_batches)\n",
    "        #Remove the remainder (Filter out the ones that don't fit)\n",
    "        rep_tensor = rep_tensor[:num_batches*batch_size]\n",
    "        # return (batch_size,num_batches)\n",
    "        rep_tensor = rep_tensor.view(batch_size, -1)\n",
    "        return rep_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 128    #Input features to the LSTM\n",
    "hidden_size = 1024  #Number of LSTM units\n",
    "num_layers = 1\n",
    "num_epochs = 2\n",
    "batch_size = 20\n",
    "timesteps = 30\n",
    "learning_rate = 0.002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = TextProcess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.TextProcess object at 0x0000028EE60F28D0>\n"
     ]
    }
   ],
   "source": [
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29686\n",
      "tensor([   0,    1,    2,  ...,  878, 5289,    5])\n",
      "29686\n",
      "1484\n"
     ]
    }
   ],
   "source": [
    "rep_tensor=corpus.get_data(r'N:\\deep learning\\alice.txt',batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 1484])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rep_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "ep_tensor = torch.LongTensor([1,2,3,4,5,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ep_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ep_tensor.view(3,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_tensor = torch.LongTensor(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8030593375117209458, 7595074916499857517, 8392569455039636854,\n",
       "        7309940765158368800, 8317701149879002209, 4981032200866521460,\n",
       "        8367815051375374456, 7305521896674583912, 7307484159728885874,\n",
       "        7070773959523001452, 2336349463739965541, 7935454042726100852,\n",
       "        7381153989982842229, 8319403537510788896, 8007514913507713070,\n",
       "        8316213871474930805, 7310503572383228192, 7957688057596965742,\n",
       "        2334956330917912948, 8461244959899871348, 8367813930434720613,\n",
       "        7954894511893669224, 7358992207844042272, 2335225676751204975,\n",
       "        7307186191138778994])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 1484])\n"
     ]
    }
   ],
   "source": [
    "print(rep_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5290\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(corpus.dictionary)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n"
     ]
    }
   ],
   "source": [
    "num_batches = rep_tensor.shape[1] // timesteps\n",
    "print(num_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.TextProcess at 0x28ee5fbc668>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TextGenerator(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, num_layers):\n",
    "        super(TextGenerator, self).__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, x, h):\n",
    "        # Perform Word Embedding \n",
    "        x = self.embed(x)\n",
    "        #Reshape the input tensor\n",
    "        #x = x.view(batch_size,timesteps,embed_size)\n",
    "        out, (h, c) = self.lstm(x, h)\n",
    "        # Reshape the output from (samples,timesteps,output_features) to a shape appropriate for the FC layer \n",
    "        # (batch_size*timesteps, hidden_size)\n",
    "        out = out.reshape(out.size(0)*out.size(1), out.size(2))\n",
    "        # Decode hidden states of all time steps\n",
    "        out = self.linear(out)\n",
    "        return out, (h, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TextGenerator(vocab_size, embed_size, hidden_size, num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detach(states):\n",
    "    \"\"\"\n",
    "If we have a tensor z,'z.detach()' returns a tensor that shares the same storage\n",
    "as 'z', but with the computation history forgotten. It doesn't know anything\n",
    "about how it was computed. In other words, we have broken the tensor z away from its past history\n",
    "Here, we want to perform truncated Backpropagation\n",
    "TBPTT splits the 1,000-long sequence into 50 sequences (say) each of length 20 and treats each sequence of length 20 as \n",
    "a separate training case. This is a sensible approach that can work well in practice, but it is blind to temporal \n",
    "dependencies that span more than 20 timesteps.\n",
    "    \"\"\"\n",
    "    return [state.detach() for state in states]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sai ram\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Loss: 8.5789\n",
      "Epoch [2/2], Loss: 5.8857\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    # Set initial hidden and cell states\n",
    "    states = (torch.zeros(num_layers, batch_size, hidden_size),\n",
    "              torch.zeros(num_layers, batch_size, hidden_size))\n",
    "\n",
    "    for i in range(0, rep_tensor.size(1) - timesteps, timesteps):\n",
    "        # Get mini-batch inputs and targets\n",
    "        inputs = rep_tensor[:, i:i+timesteps]  \n",
    "        targets = rep_tensor[:, (i+1):(i+1)+timesteps]\n",
    "        \n",
    "        outputs,_ = model(inputs, states)\n",
    "        loss = loss_fn(outputs, targets.reshape(-1))\n",
    "\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        #Perform Gradient Clipping. clip_value (float or int) is the maximum allowed value of the gradients \n",
    "        #The gradients are clipped in the range [-clip_value, clip_value]. This is to prevent the exploding gradient problem\n",
    "        clip_grad_norm(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "              \n",
    "        step = (i+1) // timesteps\n",
    "        if step % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Loss: {:.4f}'\n",
    "                   .format(epoch+1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5290])\n",
      "4710\n",
      "torch.Size([1, 5290])\n",
      "3930\n",
      "torch.Size([1, 5290])\n",
      "4089\n",
      "torch.Size([1, 5290])\n",
      "4118\n",
      "torch.Size([1, 5290])\n",
      "27\n",
      "torch.Size([1, 5290])\n",
      "28\n",
      "torch.Size([1, 5290])\n",
      "16\n",
      "torch.Size([1, 5290])\n",
      "1772\n",
      "torch.Size([1, 5290])\n",
      "42\n",
      "torch.Size([1, 5290])\n",
      "274\n",
      "torch.Size([1, 5290])\n",
      "3\n",
      "torch.Size([1, 5290])\n",
      "3499\n",
      "torch.Size([1, 5290])\n",
      "3\n",
      "torch.Size([1, 5290])\n",
      "4568\n",
      "torch.Size([1, 5290])\n",
      "2215\n",
      "torch.Size([1, 5290])\n",
      "3103\n",
      "torch.Size([1, 5290])\n",
      "6\n",
      "torch.Size([1, 5290])\n",
      "27\n",
      "torch.Size([1, 5290])\n",
      "161\n",
      "torch.Size([1, 5290])\n",
      "4648\n",
      "torch.Size([1, 5290])\n",
      "2446\n",
      "torch.Size([1, 5290])\n",
      "1512\n",
      "torch.Size([1, 5290])\n",
      "232\n",
      "torch.Size([1, 5290])\n",
      "446\n",
      "torch.Size([1, 5290])\n",
      "3334\n",
      "torch.Size([1, 5290])\n",
      "44\n",
      "torch.Size([1, 5290])\n",
      "1017\n",
      "torch.Size([1, 5290])\n",
      "4872\n",
      "torch.Size([1, 5290])\n",
      "9\n",
      "torch.Size([1, 5290])\n",
      "39\n",
      "torch.Size([1, 5290])\n",
      "3738\n",
      "torch.Size([1, 5290])\n",
      "4050\n",
      "torch.Size([1, 5290])\n",
      "338\n",
      "torch.Size([1, 5290])\n",
      "119\n",
      "torch.Size([1, 5290])\n",
      "2855\n",
      "torch.Size([1, 5290])\n",
      "236\n",
      "torch.Size([1, 5290])\n",
      "2507\n",
      "torch.Size([1, 5290])\n",
      "942\n",
      "torch.Size([1, 5290])\n",
      "2045\n",
      "torch.Size([1, 5290])\n",
      "1000\n",
      "torch.Size([1, 5290])\n",
      "1121\n",
      "torch.Size([1, 5290])\n",
      "562\n",
      "torch.Size([1, 5290])\n",
      "4537\n",
      "torch.Size([1, 5290])\n",
      "3\n",
      "torch.Size([1, 5290])\n",
      "2820\n",
      "torch.Size([1, 5290])\n",
      "1309\n",
      "torch.Size([1, 5290])\n",
      "1309\n",
      "torch.Size([1, 5290])\n",
      "2301\n",
      "torch.Size([1, 5290])\n",
      "1001\n",
      "torch.Size([1, 5290])\n",
      "27\n",
      "torch.Size([1, 5290])\n",
      "92\n",
      "torch.Size([1, 5290])\n",
      "3211\n",
      "torch.Size([1, 5290])\n",
      "2764\n",
      "torch.Size([1, 5290])\n",
      "2080\n",
      "torch.Size([1, 5290])\n",
      "3224\n",
      "torch.Size([1, 5290])\n",
      "1915\n",
      "torch.Size([1, 5290])\n",
      "4152\n",
      "torch.Size([1, 5290])\n",
      "3729\n",
      "torch.Size([1, 5290])\n",
      "3170\n",
      "torch.Size([1, 5290])\n",
      "5229\n",
      "torch.Size([1, 5290])\n",
      "843\n",
      "torch.Size([1, 5290])\n",
      "3884\n",
      "torch.Size([1, 5290])\n",
      "532\n",
      "torch.Size([1, 5290])\n",
      "5041\n",
      "torch.Size([1, 5290])\n",
      "2812\n",
      "torch.Size([1, 5290])\n",
      "470\n",
      "torch.Size([1, 5290])\n",
      "1450\n",
      "torch.Size([1, 5290])\n",
      "787\n",
      "torch.Size([1, 5290])\n",
      "456\n",
      "torch.Size([1, 5290])\n",
      "234\n",
      "torch.Size([1, 5290])\n",
      "3923\n",
      "torch.Size([1, 5290])\n",
      "4514\n",
      "torch.Size([1, 5290])\n",
      "238\n",
      "torch.Size([1, 5290])\n",
      "4451\n",
      "torch.Size([1, 5290])\n",
      "1847\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "130\n",
      "torch.Size([1, 5290])\n",
      "103\n",
      "torch.Size([1, 5290])\n",
      "486\n",
      "torch.Size([1, 5290])\n",
      "369\n",
      "torch.Size([1, 5290])\n",
      "214\n",
      "torch.Size([1, 5290])\n",
      "236\n",
      "torch.Size([1, 5290])\n",
      "129\n",
      "torch.Size([1, 5290])\n",
      "3679\n",
      "torch.Size([1, 5290])\n",
      "1023\n",
      "torch.Size([1, 5290])\n",
      "2295\n",
      "torch.Size([1, 5290])\n",
      "1086\n",
      "torch.Size([1, 5290])\n",
      "801\n",
      "torch.Size([1, 5290])\n",
      "11\n",
      "torch.Size([1, 5290])\n",
      "2254\n",
      "torch.Size([1, 5290])\n",
      "4430\n",
      "torch.Size([1, 5290])\n",
      "1144\n",
      "torch.Size([1, 5290])\n",
      "4019\n",
      "torch.Size([1, 5290])\n",
      "33\n",
      "torch.Size([1, 5290])\n",
      "16\n",
      "torch.Size([1, 5290])\n",
      "1282\n",
      "torch.Size([1, 5290])\n",
      "4780\n",
      "torch.Size([1, 5290])\n",
      "3519\n",
      "torch.Size([1, 5290])\n",
      "4079\n",
      "torch.Size([1, 5290])\n",
      "4425\n",
      "Sampled [100/500] words and save to results.txt\n",
      "torch.Size([1, 5290])\n",
      "1750\n",
      "torch.Size([1, 5290])\n",
      "2904\n",
      "torch.Size([1, 5290])\n",
      "2656\n",
      "torch.Size([1, 5290])\n",
      "2341\n",
      "torch.Size([1, 5290])\n",
      "308\n",
      "torch.Size([1, 5290])\n",
      "2812\n",
      "torch.Size([1, 5290])\n",
      "1407\n",
      "torch.Size([1, 5290])\n",
      "320\n",
      "torch.Size([1, 5290])\n",
      "3746\n",
      "torch.Size([1, 5290])\n",
      "75\n",
      "torch.Size([1, 5290])\n",
      "3002\n",
      "torch.Size([1, 5290])\n",
      "4084\n",
      "torch.Size([1, 5290])\n",
      "1302\n",
      "torch.Size([1, 5290])\n",
      "1983\n",
      "torch.Size([1, 5290])\n",
      "1762\n",
      "torch.Size([1, 5290])\n",
      "266\n",
      "torch.Size([1, 5290])\n",
      "4718\n",
      "torch.Size([1, 5290])\n",
      "1196\n",
      "torch.Size([1, 5290])\n",
      "3890\n",
      "torch.Size([1, 5290])\n",
      "16\n",
      "torch.Size([1, 5290])\n",
      "3162\n",
      "torch.Size([1, 5290])\n",
      "3517\n",
      "torch.Size([1, 5290])\n",
      "273\n",
      "torch.Size([1, 5290])\n",
      "3524\n",
      "torch.Size([1, 5290])\n",
      "80\n",
      "torch.Size([1, 5290])\n",
      "1185\n",
      "torch.Size([1, 5290])\n",
      "46\n",
      "torch.Size([1, 5290])\n",
      "580\n",
      "torch.Size([1, 5290])\n",
      "365\n",
      "torch.Size([1, 5290])\n",
      "5226\n",
      "torch.Size([1, 5290])\n",
      "601\n",
      "torch.Size([1, 5290])\n",
      "44\n",
      "torch.Size([1, 5290])\n",
      "294\n",
      "torch.Size([1, 5290])\n",
      "1597\n",
      "torch.Size([1, 5290])\n",
      "3523\n",
      "torch.Size([1, 5290])\n",
      "270\n",
      "torch.Size([1, 5290])\n",
      "160\n",
      "torch.Size([1, 5290])\n",
      "299\n",
      "torch.Size([1, 5290])\n",
      "1959\n",
      "torch.Size([1, 5290])\n",
      "2908\n",
      "torch.Size([1, 5290])\n",
      "343\n",
      "torch.Size([1, 5290])\n",
      "5026\n",
      "torch.Size([1, 5290])\n",
      "640\n",
      "torch.Size([1, 5290])\n",
      "1395\n",
      "torch.Size([1, 5290])\n",
      "1823\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "6\n",
      "torch.Size([1, 5290])\n",
      "272\n",
      "torch.Size([1, 5290])\n",
      "555\n",
      "torch.Size([1, 5290])\n",
      "2796\n",
      "torch.Size([1, 5290])\n",
      "2755\n",
      "torch.Size([1, 5290])\n",
      "1844\n",
      "torch.Size([1, 5290])\n",
      "285\n",
      "torch.Size([1, 5290])\n",
      "1150\n",
      "torch.Size([1, 5290])\n",
      "427\n",
      "torch.Size([1, 5290])\n",
      "96\n",
      "torch.Size([1, 5290])\n",
      "3\n",
      "torch.Size([1, 5290])\n",
      "523\n",
      "torch.Size([1, 5290])\n",
      "509\n",
      "torch.Size([1, 5290])\n",
      "866\n",
      "torch.Size([1, 5290])\n",
      "208\n",
      "torch.Size([1, 5290])\n",
      "916\n",
      "torch.Size([1, 5290])\n",
      "618\n",
      "torch.Size([1, 5290])\n",
      "1225\n",
      "torch.Size([1, 5290])\n",
      "180\n",
      "torch.Size([1, 5290])\n",
      "9\n",
      "torch.Size([1, 5290])\n",
      "1814\n",
      "torch.Size([1, 5290])\n",
      "3396\n",
      "torch.Size([1, 5290])\n",
      "532\n",
      "torch.Size([1, 5290])\n",
      "1042\n",
      "torch.Size([1, 5290])\n",
      "700\n",
      "torch.Size([1, 5290])\n",
      "1998\n",
      "torch.Size([1, 5290])\n",
      "3873\n",
      "torch.Size([1, 5290])\n",
      "1413\n",
      "torch.Size([1, 5290])\n",
      "312\n",
      "torch.Size([1, 5290])\n",
      "4404\n",
      "torch.Size([1, 5290])\n",
      "28\n",
      "torch.Size([1, 5290])\n",
      "4218\n",
      "torch.Size([1, 5290])\n",
      "677\n",
      "torch.Size([1, 5290])\n",
      "2428\n",
      "torch.Size([1, 5290])\n",
      "2554\n",
      "torch.Size([1, 5290])\n",
      "1589\n",
      "torch.Size([1, 5290])\n",
      "4861\n",
      "torch.Size([1, 5290])\n",
      "3353\n",
      "torch.Size([1, 5290])\n",
      "4710\n",
      "torch.Size([1, 5290])\n",
      "2822\n",
      "torch.Size([1, 5290])\n",
      "2296\n",
      "torch.Size([1, 5290])\n",
      "114\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "2888\n",
      "torch.Size([1, 5290])\n",
      "274\n",
      "torch.Size([1, 5290])\n",
      "1130\n",
      "torch.Size([1, 5290])\n",
      "192\n",
      "torch.Size([1, 5290])\n",
      "834\n",
      "torch.Size([1, 5290])\n",
      "2559\n",
      "torch.Size([1, 5290])\n",
      "2457\n",
      "torch.Size([1, 5290])\n",
      "1607\n",
      "torch.Size([1, 5290])\n",
      "3848\n",
      "Sampled [200/500] words and save to results.txt\n",
      "torch.Size([1, 5290])\n",
      "1290\n",
      "torch.Size([1, 5290])\n",
      "3582\n",
      "torch.Size([1, 5290])\n",
      "911\n",
      "torch.Size([1, 5290])\n",
      "3957\n",
      "torch.Size([1, 5290])\n",
      "1572\n",
      "torch.Size([1, 5290])\n",
      "2334\n",
      "torch.Size([1, 5290])\n",
      "774\n",
      "torch.Size([1, 5290])\n",
      "4397\n",
      "torch.Size([1, 5290])\n",
      "3810\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "1697\n",
      "torch.Size([1, 5290])\n",
      "1315\n",
      "torch.Size([1, 5290])\n",
      "340\n",
      "torch.Size([1, 5290])\n",
      "129\n",
      "torch.Size([1, 5290])\n",
      "160\n",
      "torch.Size([1, 5290])\n",
      "57\n",
      "torch.Size([1, 5290])\n",
      "3\n",
      "torch.Size([1, 5290])\n",
      "116\n",
      "torch.Size([1, 5290])\n",
      "285\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "3520\n",
      "torch.Size([1, 5290])\n",
      "757\n",
      "torch.Size([1, 5290])\n",
      "87\n",
      "torch.Size([1, 5290])\n",
      "87\n",
      "torch.Size([1, 5290])\n",
      "272\n",
      "torch.Size([1, 5290])\n",
      "3\n",
      "torch.Size([1, 5290])\n",
      "1387\n",
      "torch.Size([1, 5290])\n",
      "4509\n",
      "torch.Size([1, 5290])\n",
      "102\n",
      "torch.Size([1, 5290])\n",
      "1557\n",
      "torch.Size([1, 5290])\n",
      "821\n",
      "torch.Size([1, 5290])\n",
      "469\n",
      "torch.Size([1, 5290])\n",
      "1770\n",
      "torch.Size([1, 5290])\n",
      "3662\n",
      "torch.Size([1, 5290])\n",
      "3251\n",
      "torch.Size([1, 5290])\n",
      "20\n",
      "torch.Size([1, 5290])\n",
      "27\n",
      "torch.Size([1, 5290])\n",
      "28\n",
      "torch.Size([1, 5290])\n",
      "2122\n",
      "torch.Size([1, 5290])\n",
      "4242\n",
      "torch.Size([1, 5290])\n",
      "1564\n",
      "torch.Size([1, 5290])\n",
      "787\n",
      "torch.Size([1, 5290])\n",
      "1993\n",
      "torch.Size([1, 5290])\n",
      "3169\n",
      "torch.Size([1, 5290])\n",
      "3296\n",
      "torch.Size([1, 5290])\n",
      "2055\n",
      "torch.Size([1, 5290])\n",
      "624\n",
      "torch.Size([1, 5290])\n",
      "3351\n",
      "torch.Size([1, 5290])\n",
      "2007\n",
      "torch.Size([1, 5290])\n",
      "80\n",
      "torch.Size([1, 5290])\n",
      "3\n",
      "torch.Size([1, 5290])\n",
      "615\n",
      "torch.Size([1, 5290])\n",
      "3503\n",
      "torch.Size([1, 5290])\n",
      "4721\n",
      "torch.Size([1, 5290])\n",
      "5089\n",
      "torch.Size([1, 5290])\n",
      "329\n",
      "torch.Size([1, 5290])\n",
      "930\n",
      "torch.Size([1, 5290])\n",
      "340\n",
      "torch.Size([1, 5290])\n",
      "2364\n",
      "torch.Size([1, 5290])\n",
      "790\n",
      "torch.Size([1, 5290])\n",
      "4903\n",
      "torch.Size([1, 5290])\n",
      "3753\n",
      "torch.Size([1, 5290])\n",
      "427\n",
      "torch.Size([1, 5290])\n",
      "497\n",
      "torch.Size([1, 5290])\n",
      "128\n",
      "torch.Size([1, 5290])\n",
      "1194\n",
      "torch.Size([1, 5290])\n",
      "2023\n",
      "torch.Size([1, 5290])\n",
      "151\n",
      "torch.Size([1, 5290])\n",
      "1166\n",
      "torch.Size([1, 5290])\n",
      "1054\n",
      "torch.Size([1, 5290])\n",
      "97\n",
      "torch.Size([1, 5290])\n",
      "562\n",
      "torch.Size([1, 5290])\n",
      "208\n",
      "torch.Size([1, 5290])\n",
      "11\n",
      "torch.Size([1, 5290])\n",
      "2614\n",
      "torch.Size([1, 5290])\n",
      "4739\n",
      "torch.Size([1, 5290])\n",
      "3929\n",
      "torch.Size([1, 5290])\n",
      "733\n",
      "torch.Size([1, 5290])\n",
      "1534\n",
      "torch.Size([1, 5290])\n",
      "129\n",
      "torch.Size([1, 5290])\n",
      "5079\n",
      "torch.Size([1, 5290])\n",
      "1603\n",
      "torch.Size([1, 5290])\n",
      "3901\n",
      "torch.Size([1, 5290])\n",
      "3939\n",
      "torch.Size([1, 5290])\n",
      "1529\n",
      "torch.Size([1, 5290])\n",
      "137\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "165\n",
      "torch.Size([1, 5290])\n",
      "1092\n",
      "torch.Size([1, 5290])\n",
      "605\n",
      "torch.Size([1, 5290])\n",
      "2255\n",
      "torch.Size([1, 5290])\n",
      "4127\n",
      "torch.Size([1, 5290])\n",
      "5090\n",
      "torch.Size([1, 5290])\n",
      "11\n",
      "torch.Size([1, 5290])\n",
      "3971\n",
      "torch.Size([1, 5290])\n",
      "2143\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "Sampled [300/500] words and save to results.txt\n",
      "torch.Size([1, 5290])\n",
      "265\n",
      "torch.Size([1, 5290])\n",
      "449\n",
      "torch.Size([1, 5290])\n",
      "1030\n",
      "torch.Size([1, 5290])\n",
      "285\n",
      "torch.Size([1, 5290])\n",
      "4977\n",
      "torch.Size([1, 5290])\n",
      "5223\n",
      "torch.Size([1, 5290])\n",
      "1153\n",
      "torch.Size([1, 5290])\n",
      "1704\n",
      "torch.Size([1, 5290])\n",
      "3972\n",
      "torch.Size([1, 5290])\n",
      "2096\n",
      "torch.Size([1, 5290])\n",
      "1112\n",
      "torch.Size([1, 5290])\n",
      "110\n",
      "torch.Size([1, 5290])\n",
      "87\n",
      "torch.Size([1, 5290])\n",
      "30\n",
      "torch.Size([1, 5290])\n",
      "3043\n",
      "torch.Size([1, 5290])\n",
      "589\n",
      "torch.Size([1, 5290])\n",
      "550\n",
      "torch.Size([1, 5290])\n",
      "27\n",
      "torch.Size([1, 5290])\n",
      "427\n",
      "torch.Size([1, 5290])\n",
      "17\n",
      "torch.Size([1, 5290])\n",
      "4146\n",
      "torch.Size([1, 5290])\n",
      "2835\n",
      "torch.Size([1, 5290])\n",
      "9\n",
      "torch.Size([1, 5290])\n",
      "344\n",
      "torch.Size([1, 5290])\n",
      "9\n",
      "torch.Size([1, 5290])\n",
      "236\n",
      "torch.Size([1, 5290])\n",
      "4097\n",
      "torch.Size([1, 5290])\n",
      "3350\n",
      "torch.Size([1, 5290])\n",
      "1127\n",
      "torch.Size([1, 5290])\n",
      "3\n",
      "torch.Size([1, 5290])\n",
      "523\n",
      "torch.Size([1, 5290])\n",
      "4479\n",
      "torch.Size([1, 5290])\n",
      "5246\n",
      "torch.Size([1, 5290])\n",
      "2319\n",
      "torch.Size([1, 5290])\n",
      "27\n",
      "torch.Size([1, 5290])\n",
      "28\n",
      "torch.Size([1, 5290])\n",
      "1091\n",
      "torch.Size([1, 5290])\n",
      "1037\n",
      "torch.Size([1, 5290])\n",
      "833\n",
      "torch.Size([1, 5290])\n",
      "916\n",
      "torch.Size([1, 5290])\n",
      "1206\n",
      "torch.Size([1, 5290])\n",
      "16\n",
      "torch.Size([1, 5290])\n",
      "1480\n",
      "torch.Size([1, 5290])\n",
      "4384\n",
      "torch.Size([1, 5290])\n",
      "763\n",
      "torch.Size([1, 5290])\n",
      "91\n",
      "torch.Size([1, 5290])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212\n",
      "torch.Size([1, 5290])\n",
      "3\n",
      "torch.Size([1, 5290])\n",
      "4772\n",
      "torch.Size([1, 5290])\n",
      "722\n",
      "torch.Size([1, 5290])\n",
      "187\n",
      "torch.Size([1, 5290])\n",
      "2026\n",
      "torch.Size([1, 5290])\n",
      "2003\n",
      "torch.Size([1, 5290])\n",
      "33\n",
      "torch.Size([1, 5290])\n",
      "3\n",
      "torch.Size([1, 5290])\n",
      "2812\n",
      "torch.Size([1, 5290])\n",
      "1611\n",
      "torch.Size([1, 5290])\n",
      "4114\n",
      "torch.Size([1, 5290])\n",
      "959\n",
      "torch.Size([1, 5290])\n",
      "176\n",
      "torch.Size([1, 5290])\n",
      "202\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "1115\n",
      "torch.Size([1, 5290])\n",
      "1001\n",
      "torch.Size([1, 5290])\n",
      "112\n",
      "torch.Size([1, 5290])\n",
      "57\n",
      "torch.Size([1, 5290])\n",
      "632\n",
      "torch.Size([1, 5290])\n",
      "1234\n",
      "torch.Size([1, 5290])\n",
      "30\n",
      "torch.Size([1, 5290])\n",
      "27\n",
      "torch.Size([1, 5290])\n",
      "603\n",
      "torch.Size([1, 5290])\n",
      "502\n",
      "torch.Size([1, 5290])\n",
      "2565\n",
      "torch.Size([1, 5290])\n",
      "3177\n",
      "torch.Size([1, 5290])\n",
      "248\n",
      "torch.Size([1, 5290])\n",
      "3332\n",
      "torch.Size([1, 5290])\n",
      "704\n",
      "torch.Size([1, 5290])\n",
      "268\n",
      "torch.Size([1, 5290])\n",
      "602\n",
      "torch.Size([1, 5290])\n",
      "381\n",
      "torch.Size([1, 5290])\n",
      "96\n",
      "torch.Size([1, 5290])\n",
      "3\n",
      "torch.Size([1, 5290])\n",
      "3161\n",
      "torch.Size([1, 5290])\n",
      "169\n",
      "torch.Size([1, 5290])\n",
      "3207\n",
      "torch.Size([1, 5290])\n",
      "406\n",
      "torch.Size([1, 5290])\n",
      "22\n",
      "torch.Size([1, 5290])\n",
      "150\n",
      "torch.Size([1, 5290])\n",
      "189\n",
      "torch.Size([1, 5290])\n",
      "3\n",
      "torch.Size([1, 5290])\n",
      "96\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "265\n",
      "torch.Size([1, 5290])\n",
      "1834\n",
      "torch.Size([1, 5290])\n",
      "3090\n",
      "torch.Size([1, 5290])\n",
      "642\n",
      "Sampled [400/500] words and save to results.txt\n",
      "torch.Size([1, 5290])\n",
      "69\n",
      "torch.Size([1, 5290])\n",
      "42\n",
      "torch.Size([1, 5290])\n",
      "34\n",
      "torch.Size([1, 5290])\n",
      "103\n",
      "torch.Size([1, 5290])\n",
      "1909\n",
      "torch.Size([1, 5290])\n",
      "1333\n",
      "torch.Size([1, 5290])\n",
      "3033\n",
      "torch.Size([1, 5290])\n",
      "27\n",
      "torch.Size([1, 5290])\n",
      "603\n",
      "torch.Size([1, 5290])\n",
      "576\n",
      "torch.Size([1, 5290])\n",
      "4321\n",
      "torch.Size([1, 5290])\n",
      "1109\n",
      "torch.Size([1, 5290])\n",
      "1553\n",
      "torch.Size([1, 5290])\n",
      "3350\n",
      "torch.Size([1, 5290])\n",
      "1708\n",
      "torch.Size([1, 5290])\n",
      "1454\n",
      "torch.Size([1, 5290])\n",
      "77\n",
      "torch.Size([1, 5290])\n",
      "617\n",
      "torch.Size([1, 5290])\n",
      "157\n",
      "torch.Size([1, 5290])\n",
      "2812\n",
      "torch.Size([1, 5290])\n",
      "3259\n",
      "torch.Size([1, 5290])\n",
      "305\n",
      "torch.Size([1, 5290])\n",
      "1792\n",
      "torch.Size([1, 5290])\n",
      "202\n",
      "torch.Size([1, 5290])\n",
      "367\n",
      "torch.Size([1, 5290])\n",
      "1159\n",
      "torch.Size([1, 5290])\n",
      "3907\n",
      "torch.Size([1, 5290])\n",
      "202\n",
      "torch.Size([1, 5290])\n",
      "3306\n",
      "torch.Size([1, 5290])\n",
      "2100\n",
      "torch.Size([1, 5290])\n",
      "3235\n",
      "torch.Size([1, 5290])\n",
      "1993\n",
      "torch.Size([1, 5290])\n",
      "3978\n",
      "torch.Size([1, 5290])\n",
      "2849\n",
      "torch.Size([1, 5290])\n",
      "406\n",
      "torch.Size([1, 5290])\n",
      "610\n",
      "torch.Size([1, 5290])\n",
      "11\n",
      "torch.Size([1, 5290])\n",
      "1850\n",
      "torch.Size([1, 5290])\n",
      "272\n",
      "torch.Size([1, 5290])\n",
      "3\n",
      "torch.Size([1, 5290])\n",
      "4350\n",
      "torch.Size([1, 5290])\n",
      "1275\n",
      "torch.Size([1, 5290])\n",
      "2674\n",
      "torch.Size([1, 5290])\n",
      "326\n",
      "torch.Size([1, 5290])\n",
      "4516\n",
      "torch.Size([1, 5290])\n",
      "110\n",
      "torch.Size([1, 5290])\n",
      "27\n",
      "torch.Size([1, 5290])\n",
      "177\n",
      "torch.Size([1, 5290])\n",
      "610\n",
      "torch.Size([1, 5290])\n",
      "174\n",
      "torch.Size([1, 5290])\n",
      "1054\n",
      "torch.Size([1, 5290])\n",
      "1788\n",
      "torch.Size([1, 5290])\n",
      "4451\n",
      "torch.Size([1, 5290])\n",
      "2299\n",
      "torch.Size([1, 5290])\n",
      "3844\n",
      "torch.Size([1, 5290])\n",
      "651\n",
      "torch.Size([1, 5290])\n",
      "95\n",
      "torch.Size([1, 5290])\n",
      "3490\n",
      "torch.Size([1, 5290])\n",
      "4047\n",
      "torch.Size([1, 5290])\n",
      "117\n",
      "torch.Size([1, 5290])\n",
      "44\n",
      "torch.Size([1, 5290])\n",
      "202\n",
      "torch.Size([1, 5290])\n",
      "1934\n",
      "torch.Size([1, 5290])\n",
      "20\n",
      "torch.Size([1, 5290])\n",
      "13\n",
      "torch.Size([1, 5290])\n",
      "3\n",
      "torch.Size([1, 5290])\n",
      "3161\n",
      "torch.Size([1, 5290])\n",
      "4380\n",
      "torch.Size([1, 5290])\n",
      "336\n",
      "torch.Size([1, 5290])\n",
      "1786\n",
      "torch.Size([1, 5290])\n",
      "1086\n",
      "torch.Size([1, 5290])\n",
      "4429\n",
      "torch.Size([1, 5290])\n",
      "1708\n",
      "torch.Size([1, 5290])\n",
      "4588\n",
      "torch.Size([1, 5290])\n",
      "2142\n",
      "torch.Size([1, 5290])\n",
      "208\n",
      "torch.Size([1, 5290])\n",
      "441\n",
      "torch.Size([1, 5290])\n",
      "421\n",
      "torch.Size([1, 5290])\n",
      "99\n",
      "torch.Size([1, 5290])\n",
      "1091\n",
      "torch.Size([1, 5290])\n",
      "554\n",
      "torch.Size([1, 5290])\n",
      "2193\n",
      "torch.Size([1, 5290])\n",
      "4182\n",
      "torch.Size([1, 5290])\n",
      "119\n",
      "torch.Size([1, 5290])\n",
      "4619\n",
      "torch.Size([1, 5290])\n",
      "655\n",
      "torch.Size([1, 5290])\n",
      "960\n",
      "torch.Size([1, 5290])\n",
      "509\n",
      "torch.Size([1, 5290])\n",
      "2356\n",
      "torch.Size([1, 5290])\n",
      "1329\n",
      "torch.Size([1, 5290])\n",
      "367\n",
      "torch.Size([1, 5290])\n",
      "4188\n",
      "torch.Size([1, 5290])\n",
      "1944\n",
      "torch.Size([1, 5290])\n",
      "4039\n",
      "torch.Size([1, 5290])\n",
      "5232\n",
      "torch.Size([1, 5290])\n",
      "3448\n",
      "torch.Size([1, 5290])\n",
      "1466\n",
      "torch.Size([1, 5290])\n",
      "3\n",
      "torch.Size([1, 5290])\n",
      "523\n",
      "torch.Size([1, 5290])\n",
      "411\n",
      "Sampled [500/500] words and save to results.txt\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "with torch.no_grad():\n",
    "    with open('results.txt', 'w') as f:\n",
    "        # Set intial hidden ane cell states\n",
    "        state = (torch.zeros(num_layers, 1, hidden_size),\n",
    "                 torch.zeros(num_layers, 1, hidden_size))\n",
    "        # Select one word id randomly and convert it to shape (1,1)\n",
    "        input = torch.randint(0,vocab_size, (1,)).long().unsqueeze(1)\n",
    "\n",
    "        for i in range(500):\n",
    "            output, _ = model(input, state)\n",
    "            print(output.shape)\n",
    "            # Sample a word id from the exponential of the output \n",
    "            prob = output.exp()\n",
    "            word_id = torch.multinomial(prob, num_samples=1).item()\n",
    "            print(word_id)\n",
    "            # Replace the input with sampled word id for the next time step\n",
    "            input.fill_(word_id)\n",
    "\n",
    "            # Write the results to file\n",
    "            word = corpus.dictionary.idx2word[word_id]\n",
    "            word = '\\n' if word == '<eos>' else word + ' '\n",
    "            f.write(word)\n",
    "            \n",
    "            if (i+1) % 100 == 0:\n",
    "                print('Sampled [{}/{}] words and save to {}'.format(i+1, 500, 'results.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
